{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/home-data-for-ml-course/train.csv\n/kaggle/input/home-data-for-ml-course/train.csv.gz\n/kaggle/input/home-data-for-ml-course/sample_submission.csv.gz\n/kaggle/input/home-data-for-ml-course/test.csv.gz\n/kaggle/input/home-data-for-ml-course/test.csv\n/kaggle/input/home-data-for-ml-course/sample_submission.csv\n/kaggle/input/home-data-for-ml-course/data_description.txt\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read the data\nX_full = pd.read_csv('../input/home-data-for-ml-course/train.csv', index_col='Id')\nX_test = pd.read_csv('../input/home-data-for-ml-course/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\n\n# # To keep things simple, we'll use only numerical predictors\n# X = X_full.select_dtypes(exclude=['object'])\n# X_test = X_test_full.select_dtypes(exclude=['object'])\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X_full, y, train_size=0.8, test_size=0.2,\n                                                      random_state=0)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping columns having more than 100 null values\n\ncol = [c for c in X_train.columns if X_train[c].isnull().sum()>100] #X_train[X_train.columns].isnull().sum()>100\n\nred_X_train = X_train.drop(col, axis=1)\nred_X_valid = X_valid.drop(col, axis=1)\nred_X_test = X_test.drop(col, axis=1)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nobj = red_X_train.select_dtypes('object')\nobj_col= obj.columns\n#print(obj_col.shape) \n#red_X_train[obj_col].replace({np.nan:'0'}, inplace=True)\nred_X_train[obj_col]=red_X_train[obj_col].fillna('unknwon')\nred_X_valid[obj_col] = red_X_valid[obj_col].fillna('unknown')\nred_X_test[obj_col] = red_X_test[obj_col].fillna('unknown')\n\n\nonehot = OneHotEncoder(handle_unknown='ignore' , sparse = False)\noh_X_train = pd.DataFrame(onehot.fit_transform(red_X_train[obj_col]))\noh_X_valid = pd.DataFrame(onehot.transform(red_X_valid[obj_col]))\noh_X_test = pd.DataFrame(onehot.transform(red_X_test[obj_col]))\n\n\noh_X_train.index = red_X_train.index\noh_X_valid.index = red_X_valid.index\noh_X_test.index = red_X_test.index\n\n#print(red_X_train.shape)\nred_X_train = red_X_train.drop(obj_col, axis=1)\nred_X_valid = red_X_valid.drop(obj_col, axis=1)\nred_X_test = red_X_test.drop(obj_col, axis=1)\n\n#print(red_X_train.shape, oh_X_train.shape)\noh_X_train = pd.concat([red_X_train, oh_X_train], axis=1)\noh_X_valid = pd.concat([red_X_valid, oh_X_valid], axis=1)\noh_X_test = pd.concat([red_X_test, oh_X_test], axis=1)\n\n#print(oh_X_train.shape)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputing the remaining null values  \n\nfrom sklearn.impute import SimpleImputer\n \nx = SimpleImputer(strategy='mean')\nX_train_imputed = pd.DataFrame(x.fit_transform( oh_X_train ))\nX_valid_imputed = pd.DataFrame(x.transform( oh_X_valid ))\nX_test_imputed = pd.DataFrame(x.transform( oh_X_test ))\n\n\nX_train_imputed.columns = oh_X_train.columns\nX_valid_imputed.columns = oh_X_valid.columns\nX_test_imputed.columns = oh_X_test.columns\n\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\n\nxgb = XGBRegressor(n_estimators=100000, learning_rate=0.01)\nxgb.fit(X_train_imputed, y_train, early_stopping_rounds=20, eval_set=[(X_valid_imputed, y_valid)], verbose=False)\n\npred = xgb.predict(X_valid_imputed)\npreds_test = xgb.predict(X_test_imputed)\n\nprint('mean_absolute_error:')\n\n","execution_count":6,"outputs":[{"output_type":"stream","text":"mean_absolute_error:\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'mean_absolute_error' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-a2b06b97a6f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean_absolute_error:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'mean_absolute_error' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n# from sklearn.metrics import mean_absolute_error\n# from sklearn.svm import SVC\n\n# model=SVC()\n# parameters={\n#     'kernel': ['linear'],\n#     'C': [0.1]\n# }\n# cv = GridSearchCV(model,parameters,cv=5)\n# cv.fit(X_train_imputed, y_train.values.ravel())\n# pred=cv.predict(X_valid_imputed)\n# print(mean_absolute_error(y_valid,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}