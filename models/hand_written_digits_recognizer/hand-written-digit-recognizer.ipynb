{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# accuracy provided by the model : 0.99535 (Rank 333 among 2500 teams)\n# Submitted on kaggle\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import itertools\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport tensorflow as tf\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten\nfrom keras.optimizers import Adam, RMSprop\n\n\n%matplotlib inline\n\nnp.random.seed(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = train[\"label\"]\nX_train = train.drop(\"label\", axis=1)\n\n#normalisation\nX_train /= 255.0\nX_test = test/255.0\n\n#debugging\nprint(Y_train.shape)\nprint(X_train.shape)\n\n#reshaping\nX_train = np.array(X_train).reshape(-1, 28, 28 ,1)\nX_test = test.values.reshape(-1,28,28,1)\n\nrandom_seed=2\n\n#debugging\nprint(X_train.shape)\nprint(X_test.shape)\nprint(type(X_train))\nprint(type(X_test))\nplt.hist(Y_train)\nprint(Y_train.value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode labels to one hot vectors (ex : 9 -> [0,0,0,0,0,0,0,0,0,9])\nY_train = to_categorical(Y_train, num_classes=10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the train and the validation set\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.01, random_state=random_seed)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the CNN model \nmodel=Sequential()\n#model.add(describe(Conv2D()))\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10,activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# optimizer for gradient descent\noptimizer = Adam(lr=0.001)\n# Compile the model\nmodel.compile(optimizer = optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learning rate reduction so that as the gradient descent reaches towards the minima the steps taken by the gradient descent becomes small.\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n\n#early_stopping = EarlyStopping(monitor='val_acc', patience=2, verbose=1, min_delta=0.01) # for applying early stopping\n\nepochs = 50\nbatch_size = 86","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data augmentaion\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model\nmodel_fit = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n                              , callbacks=[learning_rate_reduction])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization of the model performance.\nfig, ax= plt.subplots(2,1)\nax[0].plot(model_fit.history['loss'], color='b', label='Training loss')\nax[0].plot(model_fit.history['val_loss'], color='r', label='Validation loss', axes=ax[0])\n#legend = ax[0].legend\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(model_fit.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(model_fit.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax[1].legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some rough work to visualize the errors in the predicted label.\nimport seaborn as sns\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n#print(Y_pred.shape)\n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nsns.heatmap(confusion_mtx, annot=True, fmt='d')\n\n\nerrors = ((Y_pred_classes - Y_true)!=0)\nX_val_errors = X_val[errors]\nY_val_error = Y_true[errors]\nY_pred_errors = Y_pred[errors]\nprint(Y_pred_errors[0])\nY_pred_classes_errors = Y_pred_classes[errors]\nprint(Y_pred_classes_errors[0])\nprint(Y_pred_errors[0][Y_pred_classes_errors[0]])\nprint(Y_val_error[0])\nprint(Y_pred_errors[0][(Y_val_error[0])])\nX_error_diff=[]\nfor i in range(0,len(Y_pred_errors)):\n    X_error_diff.append(Y_pred_errors[i][Y_pred_classes_errors[i]] - Y_pred_errors[i][Y_val_error[i]])\n    \n# for i in range(0,42):\n#     X_error_diff.append(Y_pred[errors][Y_pred_classes_errors[i]] - Y_pred[errors][Y_val_error[i]])\nprint(errors.sum())\n\n#fig, ax= plt.plots(2,1)\n\n\nfor i in range(0,len(X_val_errors)):\n    print(X_error_diff[i])\n    print(\"predicted value:\", Y_pred_classes_errors[i])\n    print(\"actual value:\", Y_val_error[i])\n    images=X_val[i].reshape((28,28))\n    #imgplot = \n    \n    plt.imshow((X_val[i].reshape((28,28)))*255)\n    plt.show()\n    #f.add_subplot(imgplot)\n    \n#imgplot = img.imread(images)\nprint(imgplot)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict the results and fit according to the output\nresults = model.predict(X_test)\nresults=np.argmax(results, axis=1)\nresults= pd.Series(results, name='Label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#store the results in the output file.\nsubmission = pd.concat([pd.Series(range(1,28001), name=\"ImageId\"), results], axis=1)\nsubmission.to_csv(\"Submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}